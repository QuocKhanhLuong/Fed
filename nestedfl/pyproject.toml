# =====================================================================
# Nested Early-Exit Federated Learning with Flower 1.18+
# =====================================================================

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "nestedfl"
version = "1.0.0"
description = "Nested Early-Exit Federated Learning for Edge Devices"
license = "Apache-2.0"
authors = [
    { name = "Research Team" }
]
dependencies = [
    "flwr[simulation]>=1.18.0",
    "torch>=2.0.0",
    "torchvision>=0.15.0",
    "timm>=0.9.0",
    "numpy>=1.21.0",
    "scikit-learn>=1.0.0",
]

[tool.hatch.build.targets.wheel]
packages = ["."]

[tool.flwr.app]
publisher = "research"

# Point to your ServerApp and ClientApp objects
[tool.flwr.app.components]
serverapp = "nestedfl.server_app:app"
clientapp = "nestedfl.client_app:app"

# =====================================================================
# Run Configuration
# =====================================================================
[tool.flwr.app.config]
# FL Settings
num-server-rounds = 20
fraction-train = 0.8      # 80% of clients per round
fraction-evaluate = 0.5
min-train-clients = 5     # Minimum 5 clients for aggregation

# Training
local-epochs = 5
lr = 0.003
batch-size = 32

# Dataset
dataset = "cifar100"  # or "cifar10"
num-classes = 100

# Nested Learning Parameters (Fixed based on paper analysis)
fast-lr-mult = 3.0        # Reduced from 5.0 for better stability with Non-IID
slow-update-freq = 5
use-distillation = false  # Not used in paper
cms-enabled = true       # ENABLED: EWC-like regularization suppresses learning
use-lss = true            # Re-enabled: now synced between fast/slow updates
use-dmgd = true           # Official DeepMomentumGD from nested-learning library

# =====================================================================
# Federations
# =====================================================================
[tool.flwr.federations]
default = "local-simulation"

# Local simulation with 10 clients
[tool.flwr.federations.local-simulation]
options.num-supernodes = 10

# GPU resource allocation (0.1 GPU per client = 10 clients on 1 GPU)
[tool.flwr.federations.local-simulation.options.backend.client-resources]
num-cpus = 1
num-gpus = 0.1

# Remote federation for distributed training
[tool.flwr.federations.remote-federation]
address = "<SUPERLINK-ADDRESS>:9091"
insecure = true
