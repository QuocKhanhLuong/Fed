# Nested Early-Exit Federated Learning

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 1.10+](https://img.shields.io/badge/PyTorch-1.10+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ¯ Overview

**Difficulty-Aware Federated Learning with Nested Early-Exit Networks**

Implementation of Nested Learning (NeurIPS 2025) for Federated Learning, featuring:

| Feature | Description |
|---------|-------------|
| **Nested Learning** | Multi-timescale optimization (fast/slow weights) |
| **Early-Exit MobileViTv2** | 3 exit points with difficulty-aware inference |
| **Local Surprise Signal (LSS)** | Sample importance weighting |
| **Continuum Memory System (CMS)** | 4-level memory for catastrophic forgetting |
| **QUIC Transport** | Low-latency communication with 0-RTT |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FL Server (RTX 4070)                        â”‚
â”‚  â€¢ QUIC Server (Port 4433)                                     â”‚
â”‚  â€¢ FedProx/FedDyn Aggregation                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ QUIC (0-RTT + Multiplexing)
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client 1 â”‚  â”‚ Client 2 â”‚  â”‚ Jetson Nano  â”‚
â”‚ RTX GPU  â”‚  â”‚ RTX GPU  â”‚  â”‚ Edge Device  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Each client runs:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        NestedEarlyExitTrainer               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ MobileViTv2 + Early Exit (3 exits)  â”‚    â”‚
â”‚  â”‚ Fast weights: Exit classifiers      â”‚    â”‚
â”‚  â”‚ Slow weights: Backbone              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  + LSS (Local Surprise Signal)              â”‚
â”‚  + CMS (4-level Continuum Memory)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
Fed/
â”œâ”€â”€ client/                     # FL Client
â”‚   â”œâ”€â”€ nested_trainer.py       # â­ Main trainer (LSS, CMS, DMGD)
â”‚   â”œâ”€â”€ early_exit_trainer.py   # Basic early-exit trainer
â”‚   â”œâ”€â”€ app_client.py           # CLI entry point
â”‚   â””â”€â”€ data_manager.py         # Dataset loading
â”œâ”€â”€ server/                     # FL Server
â”‚   â”œâ”€â”€ quic_server.py          # QUIC connection handler
â”‚   â””â”€â”€ feddyn_aggregator.py    # Aggregation strategies
â”œâ”€â”€ models/
â”‚   â””â”€â”€ early_exit_mobilevit.py # MobileViTv2 + 3 Early Exits
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_experiment.py       # â­ IEEE-style experiment runner
â”‚   â”œâ”€â”€ setup.sh                # Linux setup
â”‚   â””â”€â”€ setup_conda.sh          # macOS setup
â”œâ”€â”€ jetson/
â”‚   â”œâ”€â”€ run_client.sh           # â­ One-click Jetson setup
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_nested_features.py # â­ Test LSS, DMGD, CMS
â”‚   â””â”€â”€ test_model.py
â””â”€â”€ utils/
    â”œâ”€â”€ config.py               # Configuration
    â””â”€â”€ torch_compat.py         # PyTorch 1.x/2.x compatibility
```

## ğŸš€ Quick Start

### Installation

```bash
git clone https://github.com/QuocKhanhLuong/Fed.git
cd Fed

# Option 1: Conda (recommended)
./scripts/setup_conda.sh

# Option 2: pip
pip install -r requirements.txt
```

### Run Experiment (Simulation Mode)

```bash
# Quick test - 1 client, 5 rounds
python scripts/run_experiment.py \
    --mode simulation \
    --num_clients 1 \
    --num_rounds 5 \
    --dataset cifar10 \
    --batch_size 64

# Full experiment - 10 clients, non-IID
python scripts/run_experiment.py \
    --mode simulation \
    --num_clients 10 \
    --num_rounds 50 \
    --dataset cifar100 \
    --partition dirichlet \
    --alpha 0.5
```

### Run on Jetson Nano

```bash
# One-click setup and run
./jetson/run_client.sh --server <SERVER_IP>
```

## âš™ï¸ Key Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--num_clients` | 10 | Number of FL clients K |
| `--num_rounds` | 50 | Communication rounds T |
| `--local_epochs` | 5 | Local epochs E |
| `--partition` | dirichlet | Data partition (iid, dirichlet) |
| `--alpha` | 0.5 | Dirichlet Î± (lower = more non-IID) |
| `--use_lss` | True | Enable Local Surprise Signal |
| `--cms_levels` | 4 | CMS memory levels |
| `--use_dmgd` | False | Enable Deep Momentum GD |

## ğŸ”¬ Nested Learning Features (NeurIPS 2025)

### 1. Local Surprise Signal (LSS)

```python
# Weights samples by "surprise" (loss magnitude)
LSS(x) = loss(x) / E[loss]
# Higher loss = more surprising = higher weight
```

### 2. Continuum Memory System (CMS)

```python
# 4-level memory with exponential update frequencies
update_freqs = [1, 5, 25, 125]  # Steps between updates
# Fast layer: adapts immediately
# Anchor layer: preserves long-term knowledge
```

### 3. Deep Momentum GD (Optional)

```python
# MLP-based momentum instead of EMA
DeepMomentum: gradient â†’ MLP â†’ momentum_update
```

## ğŸ“Š Running Tests

```bash
# Test Nested Learning features
python tests/test_nested_features.py

# Test model training
python tests/test_model.py
```

## ğŸ“ Citation

```bibtex
@article{luong2025nestedexit,
  title={Difficulty-Aware Federated Learning with Nested Early-Exit Networks},
  author={Luong, Quoc Khanh},
  journal={IEEE Transactions on Mobile Computing},
  year={2025}
}
```

## ğŸ“„ License

MIT License - see LICENSE file for details.
